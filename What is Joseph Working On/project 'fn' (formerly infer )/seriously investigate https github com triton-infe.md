# seriously investigate https://github.com/triton-inference-server/server

[https://github.com/triton-inference-server/server](https://github.com/triton-inference-server/server)

seems to be better than tf serving and maybe torchserve?