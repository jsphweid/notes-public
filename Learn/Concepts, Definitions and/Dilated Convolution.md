# Dilated Convolution

[just a convolution operation with a modified kernel operation?](https://towardsdatascience.com/understanding-2d-dilated-convolution-operation-with-examples-in-numpy-and-tensorflow-with-d376b3972b25)

casts a wider net â€” the more layers, the more it goes up exponentially 

- Is this just to have a longer memory?