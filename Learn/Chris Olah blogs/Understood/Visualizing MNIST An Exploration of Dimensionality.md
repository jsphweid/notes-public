# Visualizing MNIST: An Exploration of Dimensionality Reduction (2014)

Starts by saying that since NNs are always highly dimensional and that humans have a hard time thinking past 3 dimensions, dimensionality reduction, is important in visualizing what is going on in a NN.

Dimensionality Reduction operates under the assumption that often highly dimensional data "occupies" a lower *sub-space*

- some dimensions express more variance (and hence are more important) than others

MNIST (784-dimensional vector) could be seen as a low dimensional [[Manifold]] "sweeping and curving through its high-dimensional embedding space"

Remember Chris says there are three primary competing narratives [[Neural Networks, Types, and Functional Programming (2015)]]