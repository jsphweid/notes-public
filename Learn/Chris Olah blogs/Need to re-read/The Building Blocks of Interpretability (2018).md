# The Building Blocks of Interpretability (2018)

[https://distill.pub/2018/building-blocks/](https://distill.pub/2018/building-blocks/)

feature visualization tells us what each neuron is doing, but it doesn't tell us much between how various neurons interact... this is what *attribution* is for.

Attribution doesn't seem to be well understood quite yet.

Need to read more...